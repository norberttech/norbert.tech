<!doctype html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <title>An√°lisis de Datos en Sistemas Transaccionales Distribuidos</title>
    <meta property="og:title" content="An√°lisis de Datos en Sistemas Transaccionales Distribuidos" />
    <meta name="twitter:title" content="An√°lisis de Datos en Sistemas Transaccionales Distribuidos" >

    <meta name="description" content="¬øTu sistema transaccional se colapsa bajo el peso de los informes? ¬øBuscas una forma de construir una fuente de datos unificada para tu sistema distribuido? Aprende c√≥mo comenzar a construir un almac√©n de datos anal√≠ticos eficiente y evitar las trampas comunes.">
    <meta property="og:description" content="¬øTu sistema transaccional se colapsa bajo el peso de los informes? ¬øBuscas una forma de construir una fuente de datos unificada para tu sistema distribuido? Aprende c√≥mo comenzar a construir un almac√©n de datos anal√≠ticos eficiente y evitar las trampas comunes.">
    <meta name="twitter:description" content="¬øTu sistema transaccional se colapsa bajo el peso de los informes? ¬øBuscas una forma de construir una fuente de datos unificada para tu sistema distribuido? Aprende c√≥mo comenzar a construir un almac√©n de datos anal√≠ticos eficiente y evitar las trampas comunes.">

    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://norbert.tech/blog/2025-08-12/es/analisis-datos-sistemas-transaccionales-distribuidos" />
    <meta property="og:image" content="https://norbert.tech/assets/images/avatar-8f3c52c37f20d07c5e1631e1512bdeca.jpeg" />
    <meta property="og:image:type" content="image/svg+xml" />
    <meta property="og:image:alt" content="Norbert Orzechowicz - Personal Website" />

    <meta name="twitter:card" content="summary_large_image">
    <meta property="twitter:url" content="https://norbert.tech/blog/2025-08-12/es/analisis-datos-sistemas-transaccionales-distribuidos" />
    <meta name="twitter:image" content="https://norbert.tech/assets/images/avatar-8f3c52c37f20d07c5e1631e1512bdeca.jpeg">
    <meta name="twitter:site" content="@norbert_tech" />
    <meta name="twitter:creator" content="@norbert_tech" />

    <link rel="apple-touch-icon" sizes="180x180" href="https://norbert.tech/assets/images/favicons/apple-touch-icon-9cae7ee880b4fe0bd755d300e1bca71e.png">
    <link rel="icon" type="image/png" sizes="32x32" href="https://norbert.tech/assets/images/favicons/favicon-32x32-b7a4ad4b584ab95534144e071f0e8587.png">
    <link rel="icon" type="image/png" sizes="16x16" href="https://norbert.tech/assets/images/favicons/favicon-16x16-154ca21abc06ae116c8d7ffc5713c000.png">
    <link rel="shortcut icon" href="https://norbert.tech/assets/images/favicons/favicon-db409885df78dea389e6d0b036da382c.ico">

            <style>
            @import url('https://fonts.googleapis.com/css2?family=Cabin:ital,wght@0,400..700;1,400..700&display=swap');
        </style>
        <link rel="stylesheet" href="https://norbert.tech/assets/styles/app-454b8d98685a9b5cef72f52b7ae839b6.css">
    
            
<script type="importmap">
{
    "imports": {
        "app": "https://norbert.tech/assets/app-930adf3462cf9ab60908eb1b74cf7ca7.js",
        "@oddbird/popover-polyfill": "https://norbert.tech/assets/vendor/@oddbird/popover-polyfill/popover-polyfill.index-7979d53637476aa204f709644aed2c19.js",
        "https://norbert.tech/assets/bootstrap.js": "https://norbert.tech/assets/bootstrap-d78d7e12c819dedf89372fb4824c072d.js",
        "htmx.org": "https://norbert.tech/assets/vendor/htmx.org/htmx.org.index-023ae86a082913526422a6063298f898.js",
        "iconify-icon": "https://norbert.tech/assets/vendor/iconify-icon/iconify-icon.index-8a41e423576dc2d752509fd455f508c1.js",
        "@symfony/stimulus-bundle": "https://norbert.tech/assets/@symfony/stimulus-bundle/loader-9311b8ea36bad0f6168e687b4d6dee73.js",
        "@hotwired/stimulus": "https://norbert.tech/assets/vendor/@hotwired/stimulus/stimulus.index-304681764684182e6662e0931532ed91.js",
        "https://norbert.tech/assets/@symfony/stimulus-bundle/controllers.js": "https://norbert.tech/assets/@symfony/stimulus-bundle/controllers-11c35dc7f11bbd855b8108888f18f9b7.js",
        "https://norbert.tech/assets/controllers/hello_controller.js": "https://norbert.tech/assets/controllers/hello_controller-55882fcad241d2bea50276ea485583bc.js",
        "https://norbert.tech/assets/controllers/syntax_highlight_controller.js": "https://norbert.tech/assets/controllers/syntax_highlight_controller-ae10e4cee8b4dedbf232536d05654062.js",
        "https://norbert.tech/assets/controllers/clipboard_controller.js": "https://norbert.tech/assets/controllers/clipboard_controller-6aefa8a9dec3271dae2f05b464bf9204.js",
        "highlight.js/lib/core": "https://norbert.tech/assets/vendor/highlight.js/lib/core-760145ef158caabe84ca07686407d093.js",
        "highlight.js/lib/languages/php": "https://norbert.tech/assets/vendor/highlight.js/lib/languages/php-c0eb2105c14097e8a5a1e9a767e8ac95.js",
        "highlight.js/styles/github-dark.min.css": "data:application/javascript,document.head.appendChild%28Object.assign%28document.createElement%28%22link%22%29%2C%7Brel%3A%22stylesheet%22%2Chref%3A%22https%3A%2F%2Fnorbert.tech%2Fassets%2Fvendor%2Fhighlight.js%2Fstyles%2Fgithub-dark.min-4b46e20f66f76e35d6454ca4f09b57c3.css%22%7D%29%29",
        "@fontsource-variable/cabin/index.min.css": "data:application/javascript,document.head.appendChild%28Object.assign%28document.createElement%28%22link%22%29%2C%7Brel%3A%22stylesheet%22%2Chref%3A%22https%3A%2F%2Fnorbert.tech%2Fassets%2Fvendor%2F%40fontsource-variable%2Fcabin%2Findex.min-08e34691d22388e6974e6cb2bfbcbfd0.css%22%7D%29%29",
        "clipboard": "https://norbert.tech/assets/vendor/clipboard/clipboard.index-925566f98181665b5a61fea1bcd9033d.js",
        "highlight.js/lib/languages/shell": "https://norbert.tech/assets/vendor/highlight.js/lib/languages/shell-664215791af27581e04813723523a355.js",
        "highlight.js/lib/languages/json": "https://norbert.tech/assets/vendor/highlight.js/lib/languages/json-9ac51ad2a97f9ce56b2f309eb64d7b04.js",
        "highlight.js/lib/languages/twig": "https://norbert.tech/assets/vendor/highlight.js/lib/languages/twig-0f3c6d18c0368650898b432b7bcf672a.js",
        "highlight.js/lib/languages/sql": "https://norbert.tech/assets/vendor/highlight.js/lib/languages/sql-09f80640dd6fe9bed6ff4eb255b13f08.js",
        "highlight.js/lib/languages/javascript": "https://norbert.tech/assets/vendor/highlight.js/lib/languages/javascript-100f963be02a503f0531e497103ff398.js",
        "highlight.js/lib/languages/xml": "https://norbert.tech/assets/vendor/highlight.js/lib/languages/xml-a2295112e12d4d01f257d59e1cfa676d.js"
    }
}
</script>
<!-- ES Module Shims: Import maps polyfill for modules browsers without import maps support -->
<script async src="https://ga.jspm.io/npm:es-module-shims@1.10.0/dist/es-module-shims.js"></script>
<link rel="modulepreload" href="https://norbert.tech/assets/app-930adf3462cf9ab60908eb1b74cf7ca7.js">
<link rel="modulepreload" href="https://norbert.tech/assets/vendor/@oddbird/popover-polyfill/popover-polyfill.index-7979d53637476aa204f709644aed2c19.js">
<link rel="modulepreload" href="https://norbert.tech/assets/bootstrap-d78d7e12c819dedf89372fb4824c072d.js">
<link rel="modulepreload" href="https://norbert.tech/assets/vendor/htmx.org/htmx.org.index-023ae86a082913526422a6063298f898.js">
<link rel="modulepreload" href="https://norbert.tech/assets/vendor/iconify-icon/iconify-icon.index-8a41e423576dc2d752509fd455f508c1.js">
<link rel="modulepreload" href="https://norbert.tech/assets/@symfony/stimulus-bundle/loader-9311b8ea36bad0f6168e687b4d6dee73.js">
<link rel="modulepreload" href="https://norbert.tech/assets/vendor/@hotwired/stimulus/stimulus.index-304681764684182e6662e0931532ed91.js">
<link rel="modulepreload" href="https://norbert.tech/assets/@symfony/stimulus-bundle/controllers-11c35dc7f11bbd855b8108888f18f9b7.js">
<link rel="modulepreload" href="https://norbert.tech/assets/controllers/hello_controller-55882fcad241d2bea50276ea485583bc.js">
<script type="module">import 'app';</script>
                <script defer src="https://cloud.umami.is/script.js" data-website-id="9fed007d-d990-428b-b5d9-11c6ff55a3f1"></script>
    </head>
<body class="scroll-smooth text-black relative min-h-screen pb-16">
    <div class="sticky top-0 max-h-screen overflow-y-auto bg-white py-2 px-2 border-b border-gray-500 z-[9999] print:hidden">
        <div class="grid grid-cols-2 sm:mx-auto sm:max-w-screen-2xl md:px-4">
            <div class="text-left">
                <a href="/" class="text-lg">
                    norbert.tech
                </a>
            </div>
            <div class="text-right">
                <a href="/consulting" class="text-lg inline-flex items-center space-x-1 md:mr-4 mr-2">
                    <iconify-icon icon="lineicons:consulting" class="mr-1"></iconify-icon> Consulting
                </a>
                <a href="/blog" class="text-lg inline-flex items-center space-x-1">
                    <iconify-icon icon="ooui:articles-ltr" class="mr-1"></iconify-icon> Blog
                </a>
            </div>
        </div>
    </div>
    
    <main class="mx-auto max-w-screen-2xl mb-4 md:pt-4 px-4 lg:px-0">
            <div class="mx-auto max-w-screen-lg px-2">
        <ul class="mt-2 pl-[20px] flex gap-4">
            <li>
                <a href="/blog" class="text-blue-500 hover:underline">Go Back</a>
            </li>
                                                                <li>
                        <a href="/blog/2025-08-12/pl/analiza-danych-w-rozproszonych-systemach-transakcyjnych"
                           class="text-lg hover:opacity-80"
                           title="Polish">üáµüá± Polish</a>
                    </li>
                                                                                <li>
                        <a href="/blog/2025-08-12/data-analytics-in-distributed-transactional-systems"
                           class="text-lg hover:opacity-80"
                           title="English">üá∫üá∏ English</a>
                    </li>
                                                                                <li>
                        <a href="/blog/2025-08-12/fr/analyse-donnees-systemes-transactionnels-distribues"
                           class="text-lg hover:opacity-80"
                           title="French">üá´üá∑ French</a>
                    </li>
                                                                                <li>
                        <a href="/blog/2025-08-12/de/datenanalyse-in-verteilten-transaktionssystemen"
                           class="text-lg hover:opacity-80"
                           title="Deutsch">üá©üá™ Deutsch</a>
                    </li>
                                    </ul>

                    <div class="mt-4 p-4 bg-yellow-50 border border-yellow-200 rounded-lg">
                <div class="flex items-start">
                    <div class="flex-shrink-0">
                        <svg class="h-5 w-5 text-yellow-400" viewBox="0 0 20 20" fill="currentColor">
                            <path fill-rule="evenodd" d="M8.257 3.099c.765-1.36 2.722-1.36 3.486 0l5.58 9.92c.75 1.334-.213 2.98-1.742 2.98H4.42c-1.53 0-2.493-1.646-1.743-2.98l5.58-9.92zM11 13a1 1 0 11-2 0 1 1 0 012 0zm-1-8a1 1 0 00-1 1v3a1 1 0 002 0V6a1 1 0 00-1-1z" clip-rule="evenodd"/>
                        </svg>
                    </div>
                    <div class="ml-3">
                        <h3 class="font-medium text-yellow-800">
                            Translation Notice
                        </h3>
                        <div class="mt-2 text-yellow-700">
                            <p>
                                This is an automatically translated version of that Article. Despite my best efforts, it might not be perfect.<br/>
                                Native speakers are welcome to
                                <a href="https://github.com/norberttech/norbert.tech/edit/main/templates/blog/posts/2025-08-12/analisis-datos-sistemas-transaccionales-distribuidos/post.html.twig"
                                   class="underline hover:text-yellow-800" target="_blank" rel="noopener">open pull requests
                                </a> to correct anything that doesn't sound right.
                            </p>
                        </div>
                    </div>
                </div>
            </div>
            </div>
    <article class="blog-post px-2 py-5 sm:px-4 mx-auto max-w-screen-lg">
            <div class="img-wide">
        <img src="https://norbert.tech/assets/images/blog/analytics-in-transactional-distributed-systems/analytics_01-b27f8a842f645a9c7d9901f3fd11fde8.jpg" alt="An√°lisis de datos en sistemas transaccionales distribuidos" />
    </div>

    <h1 class="font-bold text-4xl mb-2" id="title">An√°lisis de Datos en Sistemas Transaccionales Distribuidos</h1>
    <div class="mb-2">
        <small class="text-sm">Fecha de Publicaci√≥n August 12, 2025 00:00</small>
    </div>
    <div class="mb-4">
                    <small><span class="badge badge-info">an√°lisis de datos</span></small>
                    <small><span class="badge badge-info">almac√©n de datos</span></small>
                    <small><span class="badge badge-info">ETL</span></small>
                    <small><span class="badge badge-info">procesamiento de datos</span></small>
                    <small><span class="badge badge-info">sistemas transaccionales</span></small>
            </div>
    <p>
        En este art√≠culo abordar√© el problema del an√°lisis de datos en sistemas transaccionales distribuidos.<br/>
        Si buscas ideas para construir un almac√©n de datos centralizado que te permita recopilar datos de todo el sistema,
        independientemente de su fragmentaci√≥n y sin ahogarte en costos operacionales, este art√≠culo es para ti.
    </p>

    <h2>Todo comienza de forma inocente</h2>
    <p>
        La mayor√≠a de los sistemas que creamos d√≠a a d√≠a almacenan datos en alguna base de datos relacional.
        PostgreSQL es una opci√≥n muy popular y, al mismo tiempo, una buena elecci√≥n que en los √∫ltimos a√±os se ha convertido casi en
        el est√°ndar de la industria.
    </p>
    <p>
        La historia de la mayor√≠a de proyectos suele ser muy similar: comenzamos verificando la idea, conseguimos
        los primeros usuarios, el sistema empieza a generar ingresos, el negocio idea c√≥mo aumentar las ganancias, surgen nuevas
        funcionalidades. Cada nueva funcionalidad significa algunas tablas nuevas en la base de datos.
    </p>
    <p>
        Para acelerar el desarrollo utilizamos un ORM, generamos autom√°ticamente migraciones que crean y
        actualizan el esquema de la base de datos.
    </p>
    <p>
        Inicialmente todo va bien, las nuevas funcionalidades traen las ganancias esperadas, el negocio comienza a escalar.
        Contratamos m√°s programadores para crear m√°s funcionalidades en paralelo.
    </p>
    <p>
        De vez en cuando alguien reporta que el sistema en algunos lugares comienza a "ralentizarse", reconocimiento r√°pido, 
        diagn√≥stico a√∫n m√°s r√°pido, falta un √≠ndice en alguna tabla.
    </p>
    <p>
        En la configuraci√≥n de mapeos del ORM agregamos un √≠ndice en el campo por el cual el sistema busca datos muy frecuentemente.
        Problema resuelto.
    </p>
    <p>
        El equipo de programadores en crecimiento da mucha importancia a la calidad, tal vez incluso utiliza
        t√©cnicas avanzadas de desarrollo de software, como Event Storming o Domain-Driven Design.<br/>
        El CI/CD ejecuta incontables pruebas, asegur√°ndose de que los cambios no introduzcan regresiones.
    </p>
    <p>
        El idilio dura, el equipo o quiz√°s varios equipos comienzan a agregar nuevos m√≥dulos al sistema. M√≥dulos apropiadamente
        aislados, responsables de tareas espec√≠ficas, nunca traspasando sus l√≠mites y no entrometi√©ndose
        en las competencias de otros m√≥dulos.
    </p>
    <p>
        Para la comunicaci√≥n se utilizan naturalmente colas, implementamos el
        <a href="https://event-driven.io/en/outbox_inbox_patterns_and_delivery_guarantees_explained/" target="_blank">Patr√≥n Outbox/Inbox</a>
    </p>
    <p>
        Para asegurar el aislamiento apropiado, establecemos reglas que dicen que cada m√≥dulo tiene acceso √∫nicamente
        a aquellas tablas en la base de datos que le pertenecen. Para obtener datos de otro m√≥dulo es necesario
        dirigirse a ese m√≥dulo, ya sea a trav√©s de alguna API interna o de cualquier otra manera.
    </p>
    <p>
        De vez en cuando el negocio viene a nosotros con la pregunta <strong>¬øpueden generar r√°pidamente para nosotros este
            informe?</strong>.
        Por supuesto, unas pocas l√≠neas de SQL, tal vez algunas decenas y el informe est√° listo.
    </p>
    <p>
        El negocio satisfecho, el informe en formato CSV va a Excel (la herramienta de BI m√°s popular), el negocio saca
        conclusiones,
        planifica nuevas funcionalidades y cambios.
    </p>
    <div class="img-wide">
        <img src="https://norbert.tech/assets/images/blog/analytics-in-transactional-distributed-systems/happy_business_01-4fb1ffd438d7889256901278c0d60981.jpg" alt="Business Intelligence" />
    </div>

    <h2>El tiempo pasa, las nuevas tablas brotan como hongos despu√©s de la lluvia</h2>
    <p>
        En esta situaci√≥n podemos permanecer mucho tiempo, incluso varios a√±os buenos.
    </p>
    <p>
        Mientras tanto, alguien en alg√∫n lugar seguramente tendr√° la idea de agregar al sistema la posibilidad de generar informes.
        Es solo cuesti√≥n de tiempo.
    </p>
    <p>
        Los informes sobre el estado del sistema son para el negocio una de las herramientas m√°s cruciales que proporcionan visi√≥n de comportamientos,
        preferencias
        o tendencias de usuarios. Permiten no solo entender qu√© est√° pasando, sino tambi√©n planificar apropiadamente lo que est√°
        por suceder.
    </p>
    <p>
        Mientras mejores y m√°s detallados sean los informes, mejores decisiones se pueden tomar bas√°ndose en ellos. Buenas
        decisiones empresariales se traducen en mayores ganancias, mayores ganancias se traducen en mayor presupuesto.
        Mayor presupuesto se traduce en mejores herramientas, equipos m√°s grandes, mejores salarios o bonos.
    </p>
    <p>
        En el inter√©s de cada programador deber√≠a estar entonces proporcionar al negocio los datos m√°s buenos y 
        precisos posibles, despu√©s de todo mejores resultados se traducen directamente en mejores ganancias.
    </p>
    <h2>Primeros s√≠ntomas</h2>
    <p>
        El sistema funciona, genera ganancias. Consiste en alrededor de 5, tal vez incluso 10 m√≥dulos, cada m√≥dulo consiste en 20-50
        tablas en
        la base de datos. Cada m√≥dulo proporciona sus propios informes.
    </p>
    <ul>
        <li>Ventas</li>
        <li>Marketing</li>
        <li>Log√≠stica</li>
        <li>Inventarios</li>
        <li>Usuarios</li>
    </ul>
    <p>
        Cada m√≥dulo expone solo parte de los datos, una fracci√≥n de la imagen m√°s grande, ninguno sin embargo da una vista de la totalidad.
    </p>
    <p>
        Los equipos implementaron claves de referencia a datos provenientes de otros m√≥dulos, incluso lograron
        crear en la interfaz de usuario un lugar desde el cual se pueden generar informes.
    </p>
    <p>
        Pero esto sigue siendo insuficiente...
    </p>
    <p>
        Muy r√°pidamente resulta que los informes generados en diferentes m√≥dulos, escritos por diferentes programadores, 
        quiz√°s incluso en diferentes tecnolog√≠as tienen diferentes formatos de datos, diferentes est√°ndares de nomenclatura.
    </p>
    <p>
        Los rangos de fechas se interpretan de manera diferente, un m√≥dulo incluye las fechas de inicio y fin, otro las excluye,
        y otro m√°s hace un intervalo abierto por la derecha para facilitar la paginaci√≥n, porque tambi√©n tienen
        API y ese API utiliza el mismo pedazo de c√≥digo.
    </p>
    <p>
        Dado que cada m√≥dulo es independiente, posee sus l√≠mites, su nomenclatura, en cierto momento nos orientamos
        que lo que en un m√≥dulo llamamos de cierta manera, otro m√≥dulo lo expone bajo un nombre completamente diferente.
        Porque en el contexto de ese m√≥dulo tiene sentido.
    </p>
    <p>
        Con el tiempo probablemente tambi√©n nos orientemos que cada equipo defini√≥ de manera diferente su pol√≠tica de retenci√≥n y
        almacenamiento de datos.
        A pesar de tener en el m√≥dulo clave datos de los √∫ltimos 5 a√±os, no podemos hacer nada con ellos, porque los m√≥dulos que proporcionaban
        datos necesarios para enriquecer el informe b√°sico, poseen datos √∫nicamente de los √∫ltimos 2 a√±os.
    </p>
    <p>
        Sin embargo, estos no son problemas que un poco de magia en Excel no pueda resolver (tal vez excepto las faltas
        en los datos).
        A estas columnas les cambiaremos los nombres, estas las eliminaremos, agregaremos un filtrado r√°pido y ya est√°.
    </p>
    <p>
        Crearemos un gran archivo en el cual tendremos una hoja llamada "Dashboard", y todas las
        otras ser√°n solo de lectura, alimentar√°n el dashboard.
    </p>
    <p>
        Tal vez este enfoque incluso funcione por un tiempo. Tal vez incluso m√°s que un tiempo, pero no nos hagamos ilusiones.
        Todo esto al final fallar√°, y seg√∫n las leyes de
        <a href="https://en.wikipedia.org/wiki/Murphy%27s_law" target="_blank">Murphy</a>
        fallar√° en el peor momento posible.
    </p>
    <h2>¬øQu√© hay de malo en Excel?</h2>
    <p>
        ¬°Nada! Excel es una herramienta fant√°stica. El problema no est√° en Excel, sino en su utilizaci√≥n.
    </p>
    <p>
        Toda esa magia que consiste en limpiar y preparar datos no deber√≠a tener lugar en Excel, no
        a gran escala. Si hablamos de un informe r√°pido de una sola vez, no hay problema. Hacemos lo que debemos,
        creamos f√≥rmulas, analizamos datos y lo olvidamos.
    </p>
    <p>
        Sin embargo, si esto va a ser parte de nuestra rutina diaria, si c√≠clicamente debemos pasar por el mismo
        proceso, siguiendo los cambios constantes y la evoluci√≥n del sistema, m√°s temprano que tarde resultar√° que esas hojas est√°n
        desactualizadas.
    </p>
    <p>
        Las columnas dejaron de existir o cambiaron nombres, surgieron nuevas columnas, el formato de datos cambi√≥ o
        lo que es peor, uno de los equipos encargado de uno de los m√≥dulos elimin√≥ algunos datos sin conciencia de que estaban siendo utilizados
        por alg√∫n usuario empresarial en alg√∫n lugar en uno de sus informes, que abre una vez por trimestre.
    </p>
    <p>
        A largo plazo, las hojas de c√°lculo m√°s complejas que extraen datos de informes generados autom√°ticamente por
        el sistema, que luego se unen bas√°ndose en reglas impl√≠citas, son imposibles de mantener.
    </p>
    <h2>¬øEntonces conectamos alguna herramienta de BI?</h2>
    <p>
        Pensaron muchos programadores que se han enfrentado repetidamente al problema de generar informes.
    </p>
    <p>
        Tomemos por ejemplo <a href="https://www.metabase.com/" target="_blank">Metabase</a>. Una herramienta gratuita que
        podemos configurar en minutos usando Docker.
    </p>
    <p>
        Darle acceso a nuestra base y a algunas o todas las tablas, y a trav√©s de una interfaz de usuario muy amigable
        el negocio podr√° generar de manera muy f√°cil y placentera los informes m√°s complicados.
    </p>
    <p>
        ¬°Informes que podr√°n contener datos de varios m√≥dulos al mismo tiempo!
    </p>
    <p>
        Incluso podemos contratar un analista de datos con fundamentos de SQL, que todo lo que no se pueda hacer clic,
        lo logre a trav√©s de una consulta apropiadamente preparada.
    </p>
    <h2>Pero eso no resuelve el problema</h2>
    <p>
        Solo lo posterga en el tiempo.
    </p>
    <p>
        Si miramos exactamente qu√© cambi√≥, solo cambi√≥ una cosa. La herramienta...
        Trasladamos el problema de limpieza y uni√≥n de datos de Excel a Metabase.
    </p>
    <p>
        Excel ciertamente volvi√≥ a su papel original, ahora podemos poner los informes descargados de Metabase en Excel.
    </p>
    <p>
        Sin embargo, nuestra l√≥gica impl√≠cita de uni√≥n/limpieza de datos se traslad√≥ de la hoja de c√°lculo a las consultas
        SQL.
    </p>
    <p>
        Adem√°s, todos los problemas siguieron siendo los mismos:
    </p>
    <ul>
        <li>inconsistencia de datos</li>
        <li>inconsistencia de nomenclatura</li>
        <li>falta de pol√≠tica unificada de compatibilidad hacia atr√°s</li>
        <li>falta de pol√≠tica unificada de retenci√≥n de datos</li>
    </ul>
    <h2>¬øEntonces establecemos procesos y reglas?</h2>
    <p>
        La mayor√≠a de los problemas anteriores se pueden resolver implementando procesos y reglas apropiados.
    </p>
    <p>
        Podemos establecer est√°ndares de nomenclatura que digan que cada tabla en la base debe contener en el nombre el prefijo del m√≥dulo, y
        las columnas se nombran con letras min√∫sculas y separadas por guiones bajos.
    </p>
    <p>
        Podemos establecer que cada m√≥dulo almacena datos de los √∫ltimos 5 a√±os (hot storage), todo lo m√°s antiguo se
        archiva. (cold storage)
    </p>
    <p>
        Podemos establecer que los rangos de fechas siempre se tratan como intervalos abiertos por la derecha.
    </p>
    <p>
        Podemos establecer que no eliminamos ninguna columna de la base de datos, o que antes de eliminar cualquier cosa primero
        entramos en un per√≠odo de transici√≥n, durante el cual mostramos a cada usuario del sistema
        qu√© columnas cambiar√°n y de qu√© manera.
    </p>
    <p>
        Incluso si asumimos para prop√≥sitos de discusi√≥n que logramos implementar estos procesos globalmente entre varios
        equipos,
        y que estos equipos los seguir√°n absoluta y muy precisamente, <strong>eso no ser√° suficiente...</strong>
    </p>
    <h2>Escalar la base de datos no es barato</h2>
    <p>
        Especialmente si nos basamos en soluciones en la nube.
    </p>
    <p>
        Imaginemos una situaci√≥n en la cual en las horas pico de trabajo del sistema (cuando los usuarios generan m√°s
        transacciones)
        un analista empresarial, que trabaja seg√∫n su propio plan debe generar un informe basado en un t√≠pico SQL
        de miles de l√≠neas.
    </p>
    <p>
        El analista ejecuta la consulta, la base de datos comienza a trabajar duro. La consulta dura 5, 10, 15 minutos.
        La base de datos comienza a sudar.
    </p>
    <p>
        Los usuarios bombardean el sistema con nuevos pedidos (o cualquier otra operaci√≥n que genere muchas
        escrituras)
        mientras el analista espera los resultados.
    </p>
    <p>
        En el mismo momento alguien del negocio necesita verificar r√°pidamente varios informes, cada uno contiene
        "el n√∫mero total de filas en la tabla".
        Hay varias de estas personas.
    </p>
    <p>
        Todas estas operaciones se superponen entre s√≠, nuestra ya muy cargada base de datos no puede manejar.
    </p>
    <p>
        Algunas transacciones de usuarios no se completan. <br/>
        El sistema apenas respira. El tiempo de espera para las operaciones m√°s b√°sicas se mide en segundos.
    </p>
    <p>
        Y ahora la cereza del pastel, cuando todas estas escenas dantescas tienen lugar, cuando Pager Duty est√° al rojo vivo
        de todo tipo de incidentes, cuando los equipos en p√°nico tratan de revivir el sistema,
        los devops combinan c√≥mo escalar r√°pidamente la base de datos...
    </p>
    <div class="img-wide">
        <img class="mt-[-150px]" src="https://norbert.tech/assets/images/blog/analytics-in-transactional-distributed-systems/construction_01-59e51f16aa79ecadc241f490217f29a0.jpg" alt="Trabajos de mantenimiento" />
    </div>
    <p>
        El CEO comienza una presentaci√≥n para un potencial socio empresarial, con quien la cooperaci√≥n
        resulta ser clave en la estrategia de desarrollo de la empresa...
    </p>
    <h2>¬øEntonces simplemente configuramos una r√©plica?</h2>
    <p>
        Despu√©s de todo, los informes no sobrecargar√°n nuestra base transaccional.
    </p>
    <p>
        Duplicaremos los costos de mantenimiento de la base de datos, pero reduciremos el riesgo de sobrecargar el sistema y podremos
        conectar la herramienta de business intelligence favorita directamente a la r√©plica, lo que nos dar√° datos en tiempo real.
    </p>
    <p>
        Suena fant√°stico, pero en la pr√°ctica no es tan simple.
    </p>
    <p>
        Dejando de lado incluso los problemas potenciales resultantes de la naturaleza misma de la replicaci√≥n, el problema principal y fundamental
        con el que me encuentro m√°s frecuentemente es la <strong>percepci√≥n</strong>.
    </p>
    <p>
        De manera completamente diferente mirar√° las tablas en la base de datos el programador que gener√≥ esas tablas usando
        mapeos de ORM, que el analista de datos.
    </p>
    <p>
        El programador sabr√° qu√© tablas conectar juntas para obtener la imagen completa.
        Entender√° las limitaciones y condiciones enterradas en alg√∫n lugar del c√≥digo de la aplicaci√≥n.
        Sobre todo, el programador conoce o al menos deber√≠a orientarse sobre c√≥mo se ve el ciclo de vida del sistema (sus
        datos).
    </p>
    <p>
        Todo este conocimiento frecuentemente no est√° disponible para los analistas.
    </p>
    <p>
        Es como decirle a alguien que mire algo a trav√©s del ojo de la cerradura. Algo seguramente se puede ver.
        Algunas conclusiones se pueden extraer, pero ser√° muy dif√≠cil reconstruir la totalidad.
    </p>
    <p>
        Basta con que tengamos en la base de datos una columna de tipo JSONB en la cual almacenamos algunas estructuras de datos.
        Asumamos que el sistema permite 3 combinaciones correctas de la misma estructura, pero una es s√∫per rara, tan
        rara que a√∫n no ha ocurrido en el sistema. Mirando los datos, incluso de manera integral, el analista simplemente no puede saber
        que existen 3 combinaciones de una estructura. Durante la normalizaci√≥n considerar√° 2 casos, mientras que el tercero
        se convertir√° en una bomba de tiempo que explotar√° como siempre en el momento menos esperado.
    </p>
    <p>
        En otras palabras, si tenemos en el sistema varios m√≥dulos independientes. Cada uno con su base de datos, o al menos
        sus tablas en la base. Lo que sumado nos da 200-300 tablas, la expectativa de que el analista maneje esto sin problemas,
        no cometa errores y los informes no se desv√≠en de las expectativas, es delicadamente hablando ingenua.
    </p>
    <p>
        A pesar de todo, exponer una copia/r√©plica de la base de datos para analistas y darle un nombre de 4 letras derivado
        de la palabra "analytics" sigue siendo ampliamente utilizado.
    </p>
    <p>
        Las herramientas de BI compiten en qui√©n crear√° una mejor interfaz de usuario, gracias a la cual los informes se puedan hacer con clics.
        Prometen que podremos analizar datos sin SQL.
    </p>
    <p>
        S√≠, esto puede funcionar, en muchos lugares as√≠ es como funciona. De lo que no hablamos en voz alta es:
    </p>
    <ul>
        <li>Problemas con compatibilidad hacia atr√°s y cambios en la estructura de datos</li>
        <li>Problemas con el mantenimiento apropiado / versionado / pruebas de consultas SQL gigantescas/scripts
            que normalizan datos sobre la marcha
        </li>
        <li>Las r√©plicas/Copias generan costos adicionales</li>
        <li>La reducci√≥n de recursos de r√©plicas es imposible o imposibilita generar informes en tiempos aceptables
        </li>
    </ul>
    <p>
        Lo que resulta en impacto en la calidad de datos y efectividad en la toma de decisiones empresariales.
    </p>
    <h2>¬øQu√© nos queda?</h2>
    <p>
        Tal vez primero establezcamos qu√© problemas queremos resolver en primer lugar:
    </p>
    <div class="img-wide">
        <img src="https://norbert.tech/assets/images/blog/analytics-in-transactional-distributed-systems/strategy_01-f82682bfa13643ba5b8957e806e0d823.jpg" alt="Estrategia y an√°lisis" />
    </div>
    <ol>
        <li>Analizar datos / generar informes no puede tener ning√∫n impacto en el trabajo del sistema.</li>
        <li>Los datos en los informes deben ser siempre frescos (el retraso en los datos es aceptable, establecido individualmente)</li>
        <li>Los informes deben reflejar el estado real, no distorsionado del sistema</li>
        <li>La estructura de datos debe ser resistente a regresiones</li>
        <li>Pol√≠tica consistente de retenci√≥n y archivo de datos</li>
    </ol>
    <h2>1) Separaci√≥n de Recursos</h2>
    <p>
        No es nada revolucionario, si no queremos que nuestro sistema est√© expuesto a sobrecargas
        resultantes del abuso de la base de datos a trav√©s de la generaci√≥n de informes, debemos configurar una base de datos separada.
    </p>
    <p><strong>¬øQu√© base elegir para anal√≠tica?</strong></p>
    <p>
        Este es b√°sicamente tema para un art√≠culo separado o incluso una serie de art√≠culos.
        Hay muchas soluciones, unas mejores, otras peores. No existe una
        soluci√≥n m√°gica para todos los problemas.
    </p>
    <p>
        Mi consejo, especialmente para equipos m√°s peque√±os, sin experiencia en gesti√≥n de datos es no
        lanzarse a tecnolog√≠as con las que no tienen experiencia.
    </p>
    <p>
        Lo clave es el formato apropiado de datos. Despu√©s de cambiar muchas tablas angostas por una ancha probablemente
        resultar√° que generar el mismo informe solo sin usar 20x <code>JOIN</code> ya no toma 10 minutos
        sino menos de medio segundo.
    </p>
    <p>
        ¬øY si el problema son las agregaciones, no las uniones?
    </p>
    <p>
        Entonces, en lugar de agregar sobre la marcha, es mejor preparar una tabla que contenga esos datos en forma agregada, no
        cruda.
    </p>
    <h2>2) Datos Frescos</h2>
    <p>
        Bueno, pero dado que creamos una nueva base de datos independiente, ¬øde qu√© manera nos aseguraremos de que los datos en esta
        base sean frescos y actuales?
    </p>
    <p>
        Aqu√≠ mucho depende del retraso aceptable en la sincronizaci√≥n de datos.
        Frecuentemente es suficiente que la base anal√≠tica est√© aproximadamente 24 horas detr√°s de la base transaccional. Es decir, contenga
        datos hasta "ayer", incluyendo todo "ayer".
    </p>
    <p>
        ¬øPor qu√©? Porque pocas decisiones empresariales se toman en el momento.
        Si algunas decisiones deben tomarse en tan poco tiempo, entonces se construyen las automatizaciones apropiadas.
    </p>
    <p>
        Si el retraso de 24 horas es aceptable (a veces no lo es y para eso tambi√©n hay formas),
        es suficiente que realicemos sincronizaciones varias veces al d√≠a.
        Por supuesto aqu√≠ tampoco hay regla de oro. As√≠ como no hay regla que diga qu√© tan grande rango sincronizar de una vez.
    </p>
    <p>
        Hay una buena pr√°ctica que facilita la sincronizaci√≥n. Consiste en asegurarse de que las tablas principales en
        el sistema transaccional contengan la fecha de creaci√≥n/modificaci√≥n del registro.
    </p>
    <p>
        Teniendo estas dos informaciones podemos estrechar la ventana de sincronizaci√≥n a alg√∫n per√≠odo de tiempo espec√≠fico.
    </p>
    <p>
        ¬øC√≥mo se ve esto en la pr√°ctica? Podemos por ejemplo ejecutar el proceso de sincronizaci√≥n cada 6 horas, recolectando solo registros cambiados en
        las √∫ltimas 24 horas.<br/>
        <code>Por supuesto estos son n√∫meros de ejemplo, estos valores deben establecerse bas√°ndose en el tama√±o y comportamiento de los datos.</code>
    </p>
    <p>
        ¬øPor qu√© 24 horas? Tal protecci√≥n adicional. Podr√≠amos tomar datos solo de 7 horas, pero si por cualquier
        motivo la sincronizaci√≥n no se ejecuta, y no lo detectamos, podemos perder datos.
    </p>
    <h2>3) Reflejo del Estado del Sistema</h2>
    <p>
        Mi opini√≥n sobre este tema puede parecer controvertida, pero creo que el mejor conocimiento sobre datos y comportamiento
        del sistema o m√≥dulo lo tiene el equipo que construye ese sistema/m√≥dulo.
    </p>
    <p>
        Es precisamente este equipo el que deber√≠a ser responsable de que los datos generados por el sistema o su parte
        por la cual dado equipo es responsable, lleguen al repositorio central de datos.
    </p>
    <p>
        En otras palabras, es precisamente el equipo que implementa dada funcionalidad quien deber√≠a bas√°ndose en los requisitos recopilados previamente
        transformar esos datos al formato apropiado y empujarlos hacia adelante.
    </p>
    <p>
        Esta es probablemente la manera m√°s f√°cil de asegurarse de que los datos sean completos y que los programadores del equipo dado est√©n
        conscientes de que esos datos se utilizan en alg√∫n lugar. El formato de datos anal√≠ticos se convierte para ellos en
        una especie de contrato - un contrato que deben respetar.
    </p>
    <p>
        No es muy diferente del contrato en el esquema de API.
    </p>
    <h2>4) Resistencia a regresiones</h2>
    <p>
        Este punto es probablemente el m√°s complicado. La implementaci√≥n correcta de la evoluci√≥n del esquema de datos es
        frecuentemente no tanto dif√≠cil, como problem√°tica.
    </p>
    <p>
        En gran resumen las reglas se ven as√≠:
    </p>
    <ul>
        <li>Nunca eliminamos columnas</li>
        <li>Todas las columnas que agregamos deben ser <code>nullable</code> o tener un valor por defecto</li>
        <li>Los tipos de columnas solo podemos expandirlos por ejemplo, <code>int</code> podemos cambiarlo a <code>bigint</code> pero no al rev√©s</li>
        <li>No cambiamos nombres de columnas</li>
    </ul>
    <p>
        ¬øEntonces no podemos eliminar nada?
    </p>
    <p>
        Podemos, pero no de cualquier manera. Generalmente c√≥mo y con qu√© frecuencia romperemos la compatibilidad hacia atr√°s depende solo de nosotros.
    </p>
    <p>
        Si de nuestra fuente de datos anal√≠ticos solo usamos internamente y, digamos, el analista que se ocupa de construir
        informes est√° al d√≠a con los cambios en el sistema, con la coordinaci√≥n apropiada podr√≠amos agregar
        nuevas tablas, y luego eliminar las viejas, d√°ndole tiempo para actualizar los informes.
    </p>
    <p>
        Sin embargo, si nuestra fuente de datos anal√≠ticos se utiliza para <code>Data Science</code>, pero trabajamos en un entorno
        multi-tenancy y los datos anal√≠ticos/informes se proporcionan a clientes, entonces debemos abordar el asunto de manera completamente diferente.
    </p>
    <h2>Pol√≠tica de almacenamiento y archivo de datos</h2>
    <p>
        Como mencion√© anteriormente, es muy importante que los datos en la base anal√≠tica, especialmente los proporcionados por diferentes
        m√≥dulos est√©n sujetos a las mismas reglas respecto al tiempo de almacenamiento.
    </p>
    <p>
        Si los inventarios en el sistema los mantenemos solo del √∫ltimo a√±o, y los pedidos de los √∫ltimos 5 a√±os,
        los analistas no podr√°n construir un informe que contenga datos de ambas fuentes.
    </p>
    <p>
        Es m√°s un problema de naturaleza formal que t√©cnica. Parecer√≠a que es suficiente simplemente ponerse de acuerdo,
        sin embargo en la pr√°ctica no es tan simple.
    </p>
    <p>
        Para establecer una pol√≠tica com√∫n de almacenamiento y archivo de datos es necesario tomar en cuenta no solo aspectos
        t√©cnicos, sino tambi√©n legales, empresariales o precisamente anal√≠ticos, lo que puede requerir compromisos.
    </p>
    <h2>Ejemplos</h2>
    <p>
        Veamos ahora un ejemplo simple de proceso ETL, cuya tarea es transferir datos de la base transaccional
        a la base anal√≠tica.
    </p>
    <blockquote>
        En este ejemplo utilizar√© <a href="https://flow-php.com" target="_blank">Flow PHP</a>, sin embargo no es
        algo especialmente √∫nico para PHP. En cualquier lenguaje podemos construir algo muy similar usando
        cualquier biblioteca que facilite crear aplicaciones CLI y alguna herramienta para procesamiento de datos.
    </blockquote>
    <p>
        El siguiente ejemplo (en forma ligeramente modificada) proviene de una sesi√≥n de transmisi√≥n en vivo que tuve el placer de grabar con Roland, quien maneja el canal <a href="https://nevercodealone.de/de" target="_blank">Never Code Alone</a>.
        El material de video lo encontrar√°s en YouTube bajo la frase "Flow PHP"
    </p>
    <p>
        Asumamos que as√≠ m√°s o menos se ve el formato de pedidos:
    </p>
    <pre><code class="code-shell" data-controller="syntax-highlight">schema
|-- order_id: ?uuid
|-- seller_id: uuid
|-- created_at: datetime
|-- updated_at: datetime
|-- cancelled_at: ?datetime
|-- discount: ?float
|-- email: string
|-- customer: string
|-- address: map&lt;string, string&gt;
|-- notes: list&lt;string&gt;
|-- items: list&lt;structure{sku: string, quantity: integer, price: float}&gt;</code></pre>

    <p>
        Nuestro objetivo es transferir estos pedidos a la base de datos anal√≠tica, preparemos entonces el esquema de datos
        de entrada y destino.
    </p>

    <pre><code class="code-php" data-controller="syntax-highlight">&lt;?php

declare(strict_types=1);

namespace App\DataFrames;

use Flow\ETL\Adapter\Doctrine\DbalMetadata;
use function Flow\ETL\DSL\integer_schema;
use function Flow\ETL\DSL\uuid_schema;
use function Flow\ETL\DSL\datetime_schema;
use function Flow\ETL\DSL\float_schema;
use function Flow\ETL\DSL\string_schema;
use function Flow\ETL\DSL\map_schema;
use function Flow\Types\DSL\type_map;
use function Flow\Types\DSL\type_string;
use function Flow\ETL\DSL\list_schema;
use function Flow\Types\DSL\type_list;
use function Flow\Types\DSL\type_structure;
use function Flow\Types\DSL\type_integer;
use function Flow\Types\DSL\type_float;
use function \Flow\ETL\DSL\schema;
use Flow\ETL\Schema;

final class Orders
{
    public static function sourceSchema() : Schema
    {
        return schema(
            uuid_schema(&quot;order_id&quot;),
            uuid_schema(&quot;seller_id&quot;),
            datetime_schema(&quot;created_at&quot;),
            datetime_schema(&quot;updated_at&quot;, nullable: true),
            datetime_schema(&quot;cancelled_at&quot;, nullable: true),
            float_schema(&quot;discount&quot;, nullable: true),
            string_schema(&quot;email&quot;),
            string_schema(&quot;customer&quot;),
            map_schema(&quot;address&quot;, type: type_map(key_type: type_string(), value_type: type_string())),
            list_schema(&quot;notes&quot;, type: type_list(element: type_string())),
            list_schema(&quot;items&quot;, type: type_list(element: type_structure(elements: [&quot;item_id&quot; =&gt; type_string(), &quot;sku&quot; =&gt; type_string(), &quot;quantity&quot; =&gt; type_integer(), &quot;price&quot; =&gt; type_float()]))),
        );
    }

    public static function destinationSchema() : Schema
    {
        return self::sourceSchema()
            -&gt;replace(&#039;updated_at&#039;, datetime_schema(&quot;updated_at&quot;))
            -&gt;remove(&#039;address&#039;)
            -&gt;add(
                string_schema(&#039;street&#039;, metadata: DbalMetadata::length(2048)),
                string_schema(&#039;city&#039;, metadata: DbalMetadata::length(512)),
                string_schema(&#039;zip&#039;, metadata: DbalMetadata::length(32)),
                string_schema(&#039;country&#039;, metadata: DbalMetadata::length(128)),
            )
            -&gt;remove(&#039;items&#039;)
            -&gt;add(
                uuid_schema(&#039;item_id&#039;, metadata: DbalMetadata::primaryKey()),
                string_schema(&#039;sku&#039;, metadata: DbalMetadata::length(64)),
                integer_schema(&#039;quantity&#039;),
                integer_schema(&#039;price&#039;),
                string_schema(&#039;currency&#039;, metadata: DbalMetadata::length(3)),
            )
            ;
    }
}</code></pre>

    <p>
        Notemos que la estructura de destino de la tabla ya no est√° orientada a pedidos, sino a art√≠culos pedidos.
        Nuestro objetivo es desempaquetar los art√≠culos de pedidos para que cada uno sea una fila separada.
    </p>
    <p>
        Gracias a esto el analista que deba generar un informe ya no tendr√° que idear y desempaquetar
        el json sobre la marcha.
    </p>
    <p>
        La columna Direcci√≥n tambi√©n fue dividida en varias columnas, gracias a lo cual el informe se podr√°
        filtrar m√°s f√°cilmente.
    </p>
    <p>
        Otra transformaci√≥n importante es el cambio de <code>price</code> de <code>float</code> a <code>int</code>
        mediante la multiplicaci√≥n del valor de punto flotante por 100.
    </p>
    <p>
        El √∫ltimo cambio ser√° agregar informaci√≥n sobre en qu√© moneda se proporcionan los precios. ¬øPero de d√≥nde viene esta informaci√≥n?
        Este es precisamente un detalle muy importante resultante de una implementaci√≥n no muy buena.
        En este caso espec√≠fico todos los pedidos est√°n en d√≥lares. El sistema lo sabe, los programadores lo saben,
        pero la persona que mira las tablas en la base sin contexto no necesariamente posee tal conocimiento.
    </p>
    <p>
        Nuestra estructura de destino deber√≠a verse m√°s o menos as√≠:
    </p>

    <pre><code class="code-shell" data-controller="syntax-highlight">schema
|-- order_id: uuid
|-- seller_id: uuid
|-- created_at: datetime
|-- updated_at: datetime
|-- cancelled_at: ?datetime
|-- discount: ?float
|-- email: string
|-- customer: string
|-- notes: list&lt;string&gt;
|-- street: string
|-- city: string
|-- zip: string
|-- country: string
|-- item_id: uuid
|-- sku: string
|-- quantity: integer
|-- price: integer
|-- currency: string</code></pre>

    <p>
        El siguiente paso ser√° crear la tabla apropiada en la base anal√≠tica. Podemos lograr esto relativamente
        f√°cilmente gracias al adaptador para Doctrine DBAL.
    </p>

    <pre><code class="code-php" data-controller="syntax-highlight">&lt;?php

declare(strict_types=1);

namespace App\Dbal;

use App\DataFrames\Orders;
use App\DataFrames\OrdersCSV;
use Doctrine\DBAL\Schema\Schema;
use Doctrine\Migrations\Provider\SchemaProvider as MigrationsSchemaProvider;
use function Flow\ETL\Adapter\Doctrine\to_dbal_schema_table;

final class SchemaProvider implements MigrationsSchemaProvider
{
    public const ANALYTICAL_ORDER_LINE_ITEMS = &#039;order_line_items&#039;;

    public function createSchema(): Schema
    {
        return new Schema(
            tables: [
                to_dbal_schema_table(Orders::destinationSchema(), self::ANALYTICAL_ORDER_LINE_ITEMS),
            ]
        );
    }
}</code></pre>

    <p>
        En la base anal√≠tica almacenaremos entonces una versi√≥n "simplificada" o "normalizada" de la tabla de pedidos.
        La normalizaci√≥n consiste en desempaquetar los art√≠culos del pedido y hacer de ellos filas separadas, as√≠ como
        dividir la columna "Direcci√≥n" en varias columnas.
    </p>

    <p>
        Veamos entonces el comando CLI que ser√° responsable de transferir datos de la base transaccional
        a la base anal√≠tica.
    </p>

    <pre><code class="code-php" data-controller="syntax-highlight">&lt;?php

namespace App\Command;

use App\DataFrames\Orders;
use App\DataFrames\OrdersCSV;
use App\Dbal\SchemaProvider;
use Doctrine\DBAL\Connection;
use Flow\Doctrine\Bulk\Dialect\SqliteInsertOptions;
use Flow\ETL\Rows;
use Symfony\Component\Console\Attribute\AsCommand;
use Symfony\Component\Console\Command\Command;
use Symfony\Component\Console\Helper\TableSeparator;
use Symfony\Component\Console\Input\InputInterface;
use Symfony\Component\Console\Input\InputOption;
use Symfony\Component\Console\Output\OutputInterface;
use Symfony\Component\Console\Style\SymfonyStyle;
use function Flow\ETL\Adapter\Doctrine\from_dbal_key_set_qb;
use function Flow\ETL\Adapter\Doctrine\pagination_key_desc;
use function Flow\ETL\Adapter\Doctrine\pagination_key_set;
use function Flow\ETL\Adapter\Doctrine\to_dbal_table_insert;
use function Flow\ETL\DSL\analyze;
use function Flow\ETL\DSL\constraint_unique;
use function Flow\ETL\DSL\data_frame;
use function Flow\ETL\DSL\lit;
use function Flow\ETL\DSL\ref;
use function Flow\ETL\DSL\rename_replace;
use function Flow\ETL\DSL\schema_to_ascii;
use function Flow\Types\DSL\type_datetime;

#[AsCommand(
    name: &#039;app:orders:import&#039;,
    description: &#039;Import orders from the transactional database to the analytical database.&#039;,
)]
class OrdersImportCommand extends Command
{
    public function __construct(
        private readonly Connection $transactional,
        private readonly Connection $analytical,
    )
    {
        parent::__construct();
    }

    protected function configure()
    {
        $this-&gt;addOption(&#039;start-date&#039;, null, InputOption::VALUE_REQUIRED, &#039;Start date for the data pull.&#039;, &#039;-24 hours&#039;)
            -&gt;addOption(&#039;end-date&#039;, null, InputOption::VALUE_REQUIRED, &#039;End date for the data pull.&#039;, &#039;now&#039;)
        ;
    }


    protected function execute(InputInterface $input, OutputInterface $output): int
    {
        $io = new SymfonyStyle($input, $output);

        $io-&gt;title(&#039;Importing orders&#039;);

        $startDate = type_datetime()-&gt;cast($input-&gt;getOption(&#039;start-date&#039;));
        $endDate = type_datetime()-&gt;cast($input-&gt;getOption(&#039;end-date&#039;));

        $io-&gt;progressStart();

        $report = data_frame()
            -&gt;read(
                from_dbal_key_set_qb(
                    $this-&gt;transactional,
                    $this-&gt;transactional-&gt;createQueryBuilder()
                        -&gt;select(&#039;*&#039;)
                        -&gt;from(SchemaProvider::ORDERS)
                        -&gt;where(&#039;updated_at BETWEEN :start_date AND :end_date&#039;)
                        -&gt;setParameter(&#039;start_date&#039;, $startDate-&gt;format(&#039;Y-m-d H:i:s&#039;))
                        -&gt;setParameter(&#039;end_date&#039;, $endDate-&gt;format(&#039;Y-m-d H:i:s&#039;)),
                    pagination_key_set(
                        pagination_key_desc(&#039;updated_at&#039;),
                        pagination_key_desc(&#039;order_id&#039;)
                    )
                )-&gt;withSchema(Orders::sourceSchema())
            )
            -&gt;withEntry(&#039;_address&#039;, ref(&#039;address&#039;)-&gt;unpack())
            -&gt;renameEach(rename_replace(&#039;_address.&#039;, &#039;&#039;))
            -&gt;withEntry(&#039;_item&#039;, ref(&#039;items&#039;)-&gt;expand())
            -&gt;withEntry(&#039;_item&#039;, ref(&#039;_item&#039;)-&gt;unpack())
            -&gt;renameEach(rename_replace(&#039;_item.&#039;, &#039;&#039;))
            -&gt;drop(&#039;_item&#039;, &#039;items&#039;, &#039;address&#039;)
            -&gt;withEntry(&#039;currency&#039;, lit(&#039;USD&#039;))
            -&gt;withEntry(&#039;price&#039;, ref(&#039;price&#039;)-&gt;multiply(100))
            -&gt;constrain(constraint_unique(&#039;item_id&#039;))
            -&gt;match(Orders::destinationSchema())
            -&gt;write(
                to_dbal_table_insert(
                    $this-&gt;analytical,
                    SchemaProvider::ORDER_LINE_ITEMS,
                    SqliteInsertOptions::fromArray([
                        &#039;conflict_columns&#039; =&gt; [&#039;item_id&#039;],
                    ])
                )
            )
            -&gt;run(function (Rows $rows) use ($io) {
                $io-&gt;progressAdvance($rows-&gt;count());
            }, analyze: analyze())
        ;

        $io-&gt;progressFinish();

        $io-&gt;newLine();

        $io-&gt;definitionList(
            &#039;Orders Import Summary&#039;,
            new TableSeparator(),
            [&#039;Execution time &#039; =&gt; \number_format($report-&gt;statistics()-&gt;executionTime-&gt;highResolutionTime-&gt;seconds) . &#039; seconds&#039;],
            [&#039;Memory usage &#039; =&gt; \number_format($report-&gt;statistics()-&gt;memory-&gt;max()-&gt;inMb()) . &#039; MB&#039;],
            [&#039;Rows inserted &#039; =&gt; \number_format($report-&gt;statistics()-&gt;totalRows())],
        );

        return Command::SUCCESS;
    }
}
</code></pre>

    <blockquote>
        Por supuesto esta no es la forma m√°s hermosa ni siquiera la m√°s correcta. Normalmente el comando CLI no contendr√≠a
        la definici√≥n del <code>pipeline ETL</code>, sin embargo para prop√≥sitos del ejemplo es un buen inicio.
    </blockquote>

    <p>
        Un almac√©n de datos centralizado dedicado es sin duda una opci√≥n tentadora, especialmente en lugares
        donde la falta de visibilidad imposibilita la toma eficiente de decisiones.
    </p>
    <p>
        Afortunadamente es este tipo de funcionalidad que se puede agregar b√°sicamente en cualquier etapa de la vida del proyecto.
    </p>
    <p>
        Puede requerir la introducci√≥n de procesos adicionales y cierta disciplina de los equipos, sin embargo los beneficios que fluyen de tal soluci√≥n son enormes.
    </p>
    <ul>
        <li>No hay temor de que la anal√≠tica impacte el trabajo del sistema</li>
        <li>Tenemos acceso a todos los rincones de nuestro sistema, cada microservicio o m√≥dulo</li>
        <li>Tal base de datos central es el mejor regalo para los analistas</li>
        <li>Data Science ya no consiste en quemar tiempo limpiando datos</li>
        <li>Podemos conectar f√°cil y seguramente b√°sicamente cualquier herramienta de tipo Business Intelligence</li>
        <li>Creamos una cultura de trabajo con datos dentro de nuestra organizaci√≥n</li>
    </ul>
    <p>
        Por supuesto, como todo lo nuevo, tales cambios pueden parecer dif√≠ciles de introducir.
        La falta de experiencia trabajando con datos al menos en las etapas iniciales hace que esta tarea pueda parecer
        incluso irrealizable.
    </p>
    <p>
        De mi experiencia resulta sin embargo que lo m√°s dif√≠cil es comenzar, cuando ya tenemos:
    </p>
    <ul>
        <li>Algunos primeros <code>Pipelines</code> procesando datos</li>
        <li>Algunos o varios esquemas de nuestros datos</li>
        <li>Algunas transformaciones m√°s complejas</li>
        <li>Pruebas preparadas</li>
        <li>Procesos y procedimientos establecidos</li>
    </ul>
    <p>
        El trabajo va pr√°cticamente como m√°quina.
    </p>
    <p>
        Sin embargo vale la pena recordar que no hay una soluci√≥n universal que se adapte a cada sistema.
        En cada caso es necesario adaptar el enfoque a la especificidad del sistema dado y la organizaci√≥n.
    </p>

    <h2>¬øC√≥mo empezar?</h2>
    <p>
        Si necesitas ayuda en el √°mbito de construcci√≥n de un almac√©n de datos centralizado, con gusto te ayudar√©.<br/>
        <a href="https://norbert.tech/consulting">Cont√°ctame</a>, y juntos crearemos una soluci√≥n que ser√° perfectamente adaptada a tus necesidades.
    </p>
    <p>
        Tambi√©n te animo a visitar el servidor <a href="https://discord.gg/5dNXfQyACW" target="_blank">Discord - Flow PHP</a>, donde
        podemos hablar directamente.
    </p>
    <div class="img-wide">
        <img src="https://norbert.tech/assets/images/blog/analytics-in-transactional-distributed-systems/consulting_01-fa277dfb3736a033cbfcf1ac931afb08.jpg" alt="Consultor√≠a" />
    </div>

    </article>
    <div class="mb-2 mx-auto max-w-screen-lg text-center">
        <script src="https://giscus.app/client.js"
                data-repo="norberttech/norbert.tech"
                data-repo-id="MDEwOlJlcG9zaXRvcnkyMjQ0MDQwNDA="
                data-category="Comments"
                data-category-id="DIC_kwDODWAiSM4CionD"
                data-mapping="pathname"
                data-strict="0"
                data-reactions-enabled="0"
                data-emit-metadata="0"
                data-input-position="bottom"
                data-theme="light"
                data-lang="en"
                crossorigin="anonymous"
                async>
        </script>
    </div>
    </main>

    <footer class="p-4 bg-sky-50 absolute bottom-0 w-full">
        <div class="mx-auto max-w-screen-2xl text-center">
            <a href="/">by @norbert_tech</a>
        </div>
    </footer>
</body>
</html>